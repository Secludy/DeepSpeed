# DeepSpeed ZeRO Optimization Stages

This mini-series contains three posts that explain how to enable and understand the different stages of ZeRO optimization in DeepSpeed. Each post builds on the previous one and dives into the configuration and code changes required for maximizing memory efficiency when training large models.

- [Stage 1: Partitioning Optimizer States](./stage1/README.md)
- [Stage 2: Partitioning Gradients](./stage2/README.md)
- [Stage 3: Partitioning Parameters and Offloading](./stage3/README.md)
